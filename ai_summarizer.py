#!/usr/bin/env python3
"""
ğŸ¤– AI æ‘˜è¦ç”Ÿæˆå™¨
æ”¯æŒ Claude, Gemini, OpenAI ç­‰å¤šç§ LLM
"""

import os
from typing import Dict, Optional


class AISummarizer:
    """AI æ‘˜è¦ç”Ÿæˆå™¨"""

    def __init__(self, provider: str = "claude", api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆå™¨

        Args:
            provider: æä¾›å•† (claude, gemini, openai)
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.provider = provider
        self.api_key = api_key or os.getenv('CLAUDE_API_KEY', '') if provider == 'claude' else \
                       os.getenv('GEMINI_API_KEY', '') if provider == 'gemini' else \
                       os.getenv('OPENAI_API_KEY', '')

        # é»˜è®¤æ¨¡å‹é…ç½®
        if model is None:
            model = {
                'claude': 'claude-sonnet-4-20250514',
                'gemini': 'gemini-2.0-flash-exp',
                'openai': 'gpt-4o'
            }.get(provider, 'claude-sonnet-4-20250514')

        self.model = model

    def summarize_paper(self, paper: Dict, use_hf_summary: bool = False, prev_context: str = None) -> Optional[str]:
        """
        ä¸ºè®ºæ–‡ç”Ÿæˆæ‘˜è¦

        Args:
            paper: è®ºæ–‡æ•°æ®
            use_hf_summary: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ HF æä¾›çš„ç®€çŸ­æ‘˜è¦
            prev_context: å‰ä¸€å¤©çš„æ¨é€æ‘˜è¦ï¼Œç”¨äºç”Ÿæˆæœ‰å»¶ç»­æ€§çš„è§£è¯»

        Returns:
            ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬
        """
        if use_hf_summary and paper.get('ai_summary'):
            return f"ğŸ“Œ **HF AI æ‘˜è¦**:\n{paper['ai_summary']}"

        if not self.api_key:
            print(f"âš ï¸  æœªé…ç½® {self.provider} API key")
            return None

        try:
            if self.provider == 'openai':
                return self._summarize_with_openai(paper, prev_context)
            elif self.provider == 'claude':
                return self._summarize_with_claude(paper)
            elif self.provider == 'gemini':
                return self._summarize_with_gemini(paper)
            else:
                print(f"âš ï¸  ä¸æ”¯æŒçš„ provider: {self.provider}")
                return None

        except Exception as e:
            print(f"âš ï¸  {self.provider} æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def summarize_blog(self, blog: Dict) -> Optional[str]:
        """
        ä¸ºåšå®¢æ–‡ç« ç”Ÿæˆæ‘˜è¦

        Args:
            blog: åšå®¢æ•°æ®

        Returns:
            ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬
        """
        if not self.api_key:
            return None

        # ä¼˜å…ˆä½¿ç”¨å…¨æ–‡å†…å®¹
        content = blog.get('full_content', blog.get('summary', ''))

        if not content or len(content) < 100:
            return None

        try:
            if self.provider == 'openai':
                return self._summarize_blog_with_openai(blog, content)
            elif self.provider == 'claude':
                return self._summarize_blog_with_claude(blog, content)
            elif self.provider == 'gemini':
                return self._summarize_blog_with_openai(blog, content)
            else:
                return None

        except Exception as e:
            print(f"  âš ï¸  åšå®¢æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def summarize_classic_paper(self, paper: Dict) -> Optional[str]:
        """ä¸ºç»å…¸è®ºæ–‡ç”Ÿæˆ AI è§£è¯»ï¼Œèšç„¦å†å²æ„ä¹‰"""
        if not self.api_key:
            return None

        try:
            import openai
            base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            if not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'

            client = openai.OpenAI(api_key=self.api_key, base_url=base_url)

            prompt = f"""è¯·ç”¨ä¸­æ–‡è§£è¯»è¿™ç¯‡ç»å…¸è®ºæ–‡ï¼Œ100-150 å­—ï¼š

**æ ‡é¢˜**: {paper['title']} ({paper.get('year', '')})
**ä½œè€…**: {paper['authors']}
**ç®€ä»‹**: {paper['description']}
**å…³é”®è¯**: {', '.join(paper.get('keywords', []))}

è¯·å›ç­”ï¼š
1. **å†å²åœ°ä½**ï¼šè¿™ç¯‡è®ºæ–‡åœ¨ AI å‘å±•å²ä¸Šçš„ä½ç½®
2. **æ ¸å¿ƒè´¡çŒ®**ï¼šæœ€å…³é”®çš„åˆ›æ–°ç‚¹
3. **å½“ä»Šå½±å“**ï¼šå¯¹ä»Šå¤©çš„ç ”ç©¶/å·¥ä¸šç•Œè¿˜æœ‰ä»€ä¹ˆå½±å“

ç®€æ´ç›´æ¥ã€‚"""

            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ AI ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿è§£è¯»ç»å…¸è®ºæ–‡çš„å†å²æ„ä¹‰å’Œå½“ä»£ä»·å€¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=400,
                temperature=0.7
            )

            summary = response.choices[0].message.content.strip()
            print(f"  âœ… ç»å…¸è®ºæ–‡è§£è¯»ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return f"ğŸ¤– **AI è§£è¯»**:\n\n{summary}"

        except Exception as e:
            print(f"  âš ï¸  ç»å…¸è®ºæ–‡è§£è¯»å¤±è´¥: {e}")
            return None

    def _summarize_blog_with_claude(self, blog: Dict, content: str) -> Optional[str]:
        """ä½¿ç”¨ Claude ç”Ÿæˆåšå®¢æ‘˜è¦"""
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=self.api_key)

            prompt = f"""è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“è¿™ç¯‡åšå®¢ï¼Œæ§åˆ¶åœ¨ 150-200 å­—ï¼š

**æ ‡é¢˜**: {blog['title']}
**æ¥æº**: {blog['source']}

**å†…å®¹**:
{content[:2000]}

è¯·å›ç­”ï¼š
1. **æ ¸å¿ƒè§‚ç‚¹**ï¼šæ–‡ç« ä¸»è¦è¯´äº†ä»€ä¹ˆï¼ˆ1-2 å¥ï¼‰
2. **å…³é”®å‘ç°**ï¼šæœ€é‡è¦çš„ä¿¡æ¯æˆ–ç»“è®º
3. **å€¼å¾—å…³æ³¨**ï¼šå¯¹ AI ä»ä¸šè€…çš„å¯å‘

ç®€æ´ç›´æ¥ã€‚"""

            response = client.messages.create(
                model=self.model,
                max_tokens=600,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )

            summary = response.content[0].text.strip()
            print(f"  âœ… åšå®¢æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return summary

        except Exception as e:
            print(f"  âš ï¸  Claude åšå®¢æ‘˜è¦å¤±è´¥: {e}")
            return None

    def _summarize_blog_with_openai(self, blog: Dict, content: str) -> Optional[str]:
        """ä½¿ç”¨ OpenAIï¼ˆå…¼å®¹ï¼‰ç”Ÿæˆåšå®¢æ‘˜è¦"""
        try:
            import openai

            base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            if not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'

            client = openai.OpenAI(api_key=self.api_key, base_url=base_url)

            prompt = f"""è¯·ç”¨ä¸­æ–‡ç®€è¦æ€»ç»“è¿™ç¯‡åšå®¢ï¼Œæ§åˆ¶åœ¨ 150-200 å­—ï¼š

**æ ‡é¢˜**: {blog['title']}
**æ¥æº**: {blog['source']}

**å†…å®¹**:
{content[:2000]}

è¯·å›ç­”ï¼š
1. **æ ¸å¿ƒè§‚ç‚¹**ï¼šæ–‡ç« ä¸»è¦è¯´äº†ä»€ä¹ˆï¼ˆ1-2 å¥ï¼‰
2. **å…³é”®å‘ç°**ï¼šæœ€é‡è¦çš„ä¿¡æ¯æˆ–ç»“è®º
3. **å€¼å¾—å…³æ³¨**ï¼šå¯¹ AI ä»ä¸šè€…çš„å¯å‘

ç®€æ´ç›´æ¥ã€‚"""

            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ª AI ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æ€»ç»“å’Œåˆ†ææŠ€æœ¯åšå®¢æ–‡ç« ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=600,
                temperature=0.7
            )

            summary = response.choices[0].message.content.strip()
            print(f"  âœ… åšå®¢æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return summary

        except Exception as e:
            print(f"  âš ï¸  åšå®¢æ‘˜è¦ API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_claude(self, paper: Dict) -> Optional[str]:
        """ä½¿ç”¨ Claude ç”Ÿæˆæ‘˜è¦"""
        try:
            import anthropic

            client = anthropic.Anthropic(api_key=self.api_key)
            prompt = self._build_prompt(paper)

            response = client.messages.create(
                model=self.model,
                max_tokens=2000,
                temperature=0.7,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            summary = response.content[0].text
            return f"ğŸ¤– **Claude è§£è¯»**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… anthropic åº“: pip install anthropic")
            return None
        except Exception as e:
            print(f"âš ï¸  Claude API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_gemini(self, paper: Dict) -> Optional[str]:
        """ä½¿ç”¨ Gemini ç”Ÿæˆæ‘˜è¦"""
        try:
            import google.generativeai as genai

            genai.configure(api_key=self.api_key)
            model = genai.GenerativeModel(self.model)

            prompt = self._build_prompt(paper)

            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2000,
                    temperature=0.7
                )
            )

            summary = response.text
            return f"ğŸ¤– **Gemini è§£è¯»**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… google-generativeai åº“: pip install google-generativeai")
            return None
        except Exception as e:
            print(f"âš ï¸  Gemini API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_openai(self, paper: Dict, prev_context: str = None) -> Optional[str]:
        """ä½¿ç”¨ OpenAIï¼ˆæˆ–å…¼å®¹çš„ä¸­è½¬ APIï¼‰ç”Ÿæˆæ‘˜è¦"""
        try:
            import openai

            base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            if not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'

            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=base_url
            )

            prompt = self._build_prompt(paper, prev_context)

            # æ ¹æ®æ¨¡å‹åç§°å†³å®šæ˜¾ç¤ºçš„æ ‡ç­¾
            model_name = self.model
            if 'claude' in model_name.lower():
                ai_label = "Claude è§£è¯»"
            elif 'gemini' in model_name.lower():
                ai_label = "Gemini è§£è¯»"
            elif 'gpt' in model_name.lower():
                ai_label = "GPT è§£è¯»"
            else:
                ai_label = "AI è§£è¯»"

            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ AI ç ”ç©¶åŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡ç®€æ´è§£è¯»å­¦æœ¯è®ºæ–‡ï¼Œé‡ç‚¹çªå‡ºåˆ›æ–°ç‚¹å’Œå®é™…ä»·å€¼ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=800,
                temperature=0.7
            )

            summary = response.choices[0].message.content.strip()
            print(f"  âœ… ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return f"ğŸ¤– **{ai_label}**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… openai åº“: pip install openai")
            return None
        except Exception as e:
            print(f"âš ï¸  API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _build_prompt(self, paper: Dict, prev_context: str = None) -> str:
        """æ„å»ºæç¤ºè¯"""
        context_section = ""
        if prev_context:
            context_section = f"""
**æ˜¨æ—¥æ¨é€æ‘˜è¦**ï¼ˆè¯·å‚è€ƒï¼Œä½“ç°ç ”ç©¶å»¶ç»­æ€§ï¼‰:
{prev_context}

"""

        prompt = f"""è¯·ç”¨ä¸­æ–‡ç®€è¦è§£è¯»ä»¥ä¸‹è®ºæ–‡ï¼Œæ§åˆ¶åœ¨ 200-300 å­—ï¼š
{context_section}
**æ ‡é¢˜**: {paper['title']}
**ä½œè€…**: {paper.get('author_str', 'N/A')}
**æ‘˜è¦**: {paper['summary']}

è¯·å›ç­”ï¼š
1. **åšäº†ä»€ä¹ˆ**ï¼šä¸€å¥è¯æ¦‚æ‹¬æ ¸å¿ƒå·¥ä½œ
2. **æ€ä¹ˆåšçš„**ï¼šå…³é”®æ–¹æ³•ï¼ˆ2-3 å¥ï¼‰
3. **æ•ˆæœå¦‚ä½•**ï¼šä¸»è¦ç»“æœ
4. **ä¸ºä»€ä¹ˆé‡è¦**ï¼šå¯¹é¢†åŸŸçš„æ„ä¹‰{'ï¼Œä»¥åŠä¸æ˜¨æ—¥æ¨é€å†…å®¹çš„å…³è”' if prev_context else ''}

ç®€æ´ç›´æ¥ï¼Œä¸è¦å®¢å¥—è¯ã€‚"""
        return prompt


def get_summarizer_from_env():
    """ä»ç¯å¢ƒå˜é‡è·å–æ‘˜è¦ç”Ÿæˆå™¨"""
    provider = os.getenv('AI_PROVIDER', 'claude')  # é»˜è®¤ç”¨ Claude

    # ä¼˜å…ˆè·å–ç‰¹å®š provider çš„ API keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ OPENAI_API_KEY
    api_key = os.getenv(f'{provider.upper()}_API_KEY', '') or os.getenv('OPENAI_API_KEY', '')

    # è·å–æ¨¡å‹åç§°
    model = os.getenv(f'{provider.upper()}_MODEL', None) or os.getenv('OPENAI_MODEL', None)

    # å¦‚æœéƒ½æ²¡è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not model:
        model = {
            'claude': 'claude-sonnet-4-20250514',
            'gemini': 'gemini-2.0-flash-exp',
            'openai': 'gpt-4o'
        }.get(provider, 'claude-sonnet-4-20250514')

    return AISummarizer(provider=provider, api_key=api_key, model=model)
