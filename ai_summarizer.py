#!/usr/bin/env python3
"""
ğŸ¤– AI æ‘˜è¦ç”Ÿæˆå™¨
æ”¯æŒ Claude, Gemini, OpenAI ç­‰å¤šç§ LLM
"""

import os
from typing import Dict, Optional


class AISummarizer:
    """AI æ‘˜è¦ç”Ÿæˆå™¨"""

    def __init__(self, provider: str = "claude", api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆå™¨

        Args:
            provider: æä¾›å•† (claude, gemini, openai)
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.provider = provider
        self.api_key = api_key or os.getenv('CLAUDE_API_KEY', '') if provider == 'claude' else \
                       os.getenv('GEMINI_API_KEY', '') if provider == 'gemini' else \
                       os.getenv('OPENAI_API_KEY', '')

        # é»˜è®¤æ¨¡å‹é…ç½®
        if model is None:
            model = {
                'claude': 'claude-sonnet-4-20250514',
                'gemini': 'gemini-2.0-flash-exp',
                'openai': 'gpt-4o'
            }.get(provider, 'claude-sonnet-4-20250514')

        self.model = model

    def summarize_paper(self, paper: Dict, use_hf_summary: bool = False) -> Optional[str]:
        """
        ä¸ºè®ºæ–‡ç”Ÿæˆè¯¦ç»†æ‘˜è¦

        Args:
            paper: è®ºæ–‡æ•°æ®
            use_hf_summary: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ HF æä¾›çš„ç®€çŸ­æ‘˜è¦ï¼ˆé»˜è®¤ falseï¼Œæ€»æ˜¯ç”Ÿæˆè¯¦ç»†è§£è¯»ï¼‰

        Returns:
            ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬
        """
        # å¦‚æœæ˜ç¡®è¦æ±‚ä½¿ç”¨ HF æ‘˜è¦ä¸”å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨
        if use_hf_summary and paper.get('ai_summary'):
            return f"ğŸ“Œ **HF AI æ‘˜è¦**:\n{paper['ai_summary']}"

        if not self.api_key:
            print(f"âš ï¸  æœªé…ç½® {self.provider} API key")
            return None

        # è°ƒç”¨ LLM ç”Ÿæˆè¯¦ç»†è§£è¯»
        try:
            # ä¸­è½¬ API æ¨¡å¼ï¼šä½¿ç”¨ openai å®¢æˆ·ç«¯è°ƒç”¨ä»»ä½•æ¨¡å‹
            if self.provider == 'openai':
                return self._summarize_with_openai(paper)
            elif self.provider == 'claude':
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸­è½¬ API
                if os.getenv('OPENAI_BASE_URL'):
                    # ä½¿ç”¨ä¸­è½¬ API è°ƒç”¨ Claude
                    return self._summarize_with_openai(paper)
                else:
                    # ç›´æ¥è°ƒç”¨ Claude å®˜æ–¹ API
                    return self._summarize_with_claude(paper)
            elif self.provider == 'gemini':
                return self._summarize_with_gemini(paper)
            else:
                print(f"âš ï¸  ä¸æ”¯æŒçš„ provider: {self.provider}")
                return None

        except Exception as e:
            print(f"âš ï¸  {self.provider} æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def summarize_blog(self, blog: Dict) -> Optional[str]:
        """
        ä¸ºåšå®¢æ–‡ç« ç”Ÿæˆæ‘˜è¦

        Args:
            blog: åšå®¢æ•°æ®

        Returns:
            ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬
        """
        if not self.api_key:
            return None

        # ä¼˜å…ˆä½¿ç”¨å…¨æ–‡å†…å®¹
        content = blog.get('full_content', blog.get('summary', ''))

        if not content or len(content) < 100:
            return None

        try:
            # ä½¿ç”¨ä¸­è½¬ API
            if os.getenv('OPENAI_BASE_URL') or self.provider == 'openai':
                return self._summarize_blog_with_openai(blog, content)
            elif self.provider == 'claude':
                return self._summarize_blog_with_openai(blog, content)
            else:
                return None

        except Exception as e:
            print(f"  âš ï¸  åšå®¢æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _summarize_blog_with_openai(self, blog: Dict, content: str) -> Optional[str]:
        """ä½¿ç”¨ OpenAIï¼ˆå…¼å®¹ï¼‰ç”Ÿæˆåšå®¢æ‘˜è¦"""
        try:
            import openai

            base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            if not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'

            client = openai.OpenAI(api_key=self.api_key, base_url=base_url)

            prompt = f"""è¯·è¯¦ç»†æ€»ç»“è¿™ç¯‡åšå®¢æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹ï¼š

**æ ‡é¢˜**: {blog['title']}
**æ¥æº**: {blog['source']}
**é“¾æ¥**: {blog['link']}

**æ–‡ç« å†…å®¹**:
{content[:3000]}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼ˆç”¨ä¸­æ–‡ï¼Œè¯¦ç»†è¯´æ˜ï¼‰ï¼š

## æ ¸å¿ƒè§‚ç‚¹
è¿™ç¯‡æ–‡ç« çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ

## å…³é”®ä¿¡æ¯
- ä½œè€…/å‘å¸ƒè€…
- è®¨è®ºçš„æ ¸å¿ƒé—®é¢˜
- æå‡ºçš„æ–¹æ³•æˆ–å‘ç°
- é‡è¦çš„æ•°æ®æˆ–ç»“è®º

## ä¸ªäººè§£è¯»
å¦‚æœä½ æ˜¯ AI ç ”ç©¶è€…ï¼Œä½ ä¼šå¦‚ä½•è¯„ä»·è¿™ç¯‡æ–‡ç« ï¼Ÿå®ƒå¯¹è¿™ä¸ªé¢†åŸŸæœ‰ä»€ä¹ˆå¯å‘ï¼Ÿ

ç›´æ¥è¿”å›ä¸Šè¿°æ ¼å¼çš„å†…å®¹ï¼Œå­—æ•° 500-800 å­—ã€‚"""

            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ª AI ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æ€»ç»“å’Œåˆ†ææŠ€æœ¯åšå®¢æ–‡ç« ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )

            summary = response.choices[0].message.content.strip()
            print(f"  âœ… åšå®¢æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return f"ğŸ¤– **AI è§£è¯»**:\n\n{summary}"

        except Exception as e:
            print(f"  âš ï¸  åšå®¢æ‘˜è¦ API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_claude(self, paper: Dict) -> Optional[str]:
        """ä½¿ç”¨ Claude ç”Ÿæˆæ‘˜è¦"""
        try:
            import anthropic

            client = anthropic.Anthropic(api_key=self.api_key)
            prompt = self._build_prompt(paper)

            response = client.messages.create(
                model=self.model,
                max_tokens=2000,
                temperature=0.7,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            summary = response.content[0].text
            return f"ğŸ¤– **Claude è§£è¯»**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… anthropic åº“: pip install anthropic")
            return None
        except Exception as e:
            print(f"âš ï¸  Claude API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_gemini(self, paper: Dict) -> Optional[str]:
        """ä½¿ç”¨ Gemini ç”Ÿæˆæ‘˜è¦"""
        try:
            import google.generativeai as genai

            genai.configure(api_key=self.api_key)
            model = genai.GenerativeModel(self.model)

            prompt = self._build_prompt(paper)

            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2000,
                    temperature=0.7
                )
            )

            summary = response.text
            return f"ğŸ¤– **Gemini è§£è¯»**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… google-generativeai åº“: pip install google-generativeai")
            return None
        except Exception as e:
            print(f"âš ï¸  Gemini API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _summarize_with_openai(self, paper: Dict) -> Optional[str]:
        """ä½¿ç”¨ OpenAIï¼ˆæˆ–å…¼å®¹çš„ä¸­è½¬ APIï¼‰ç”Ÿæˆæ‘˜è¦"""
        try:
            import openai

            # è·å– base_urlï¼Œç¡®ä¿åŒ…å« /v1 è·¯å¾„
            base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
            if not base_url.endswith('/v1'):
                base_url = base_url.rstrip('/') + '/v1'

            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=base_url
            )

            prompt = self._build_prompt(paper)

            # æ ¹æ®æ¨¡å‹åç§°å†³å®šæ˜¾ç¤ºçš„æ ‡ç­¾
            model_name = self.model
            if 'claude' in model_name.lower():
                ai_label = "Claude è§£è¯»"
            elif 'gemini' in model_name.lower():
                ai_label = "Gemini è§£è¯»"
            elif 'gpt' in model_name.lower():
                ai_label = "GPT è§£è¯»"
            else:
                ai_label = "AI è§£è¯»"

            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æ·±å…¥åˆ†æå’Œæ€»ç»“å­¦æœ¯è®ºæ–‡ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå›ç­”è¦è¯¦ç»†ä¸”æœ‰æ·±åº¦ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=3000,  # å¢åŠ è¾“å‡ºé•¿åº¦
                temperature=0.7
            )

            summary = response.choices[0].message.content.strip()
            print(f"  âœ… ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return f"ğŸ¤– **{ai_label}**:\n\n{summary}"

        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£… openai åº“: pip install openai")
            return None
        except Exception as e:
            print(f"âš ï¸  API è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _build_prompt(self, paper: Dict) -> str:
        """æ„å»ºæç¤ºè¯"""
        prompt = f"""è¯·æ·±å…¥åˆ†æä»¥ä¸‹è®ºæ–‡å¹¶æä¾›è¯¦ç»†çš„ä¸­æ–‡è§£è¯»ï¼š

**æ ‡é¢˜**: {paper['title']}
**ä½œè€…**: {paper.get('author_str', 'N/A')}
**å‘å¸ƒæ—¶é—´**: {paper.get('published', 'N/A')}
**åŸå§‹æ‘˜è¦**: {paper['summary']}

è¯·æŒ‰ä»¥ä¸‹ç»“æ„å›ç­”ï¼ˆæ¯éƒ¨åˆ†è¯¦ç»†è¯´æ˜ï¼Œç”¨ä¸­æ–‡ï¼‰ï¼š

## æ ¸å¿ƒé—®é¢˜
è¿™ç¯‡è®ºæ–‡è¯•å›¾è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ

## ä¸»è¦è´¡çŒ®
è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹å’Œè´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆåˆ—ä¸¾ 3-5 ç‚¹ï¼‰

## æŠ€æœ¯æ–¹æ³•
ä½¿ç”¨äº†ä»€ä¹ˆæ–¹æ³•æˆ–æŠ€æœ¯ï¼Ÿï¼ˆè¯¦ç»†è¯´æ˜ï¼‰

## å®éªŒç»“æœ
ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½è¡¨ç°å¦‚ä½•ï¼Ÿ

## ä»·å€¼æ„ä¹‰
è¿™é¡¹ç ”ç©¶çš„é‡è¦æ€§åœ¨å“ªé‡Œï¼Ÿå¯¹æœªæ¥å·¥ä½œæœ‰ä»€ä¹ˆå¯å‘ï¼Ÿ

## ä¸ªäººè§‚ç‚¹
å¦‚æœä½ æ˜¯ç ”ç©¶è€…ï¼Œä½ ä¼šå¦‚ä½•è¯„ä»·è¿™é¡¹å·¥ä½œï¼Ÿ

ç›´æ¥è¿”å›ä¸Šè¿°æ ¼å¼çš„å†…å®¹ï¼Œä¸è¦å…¶ä»–å®¢å¥—è¯ã€‚"""
        return prompt


def get_summarizer_from_env():
    """ä»ç¯å¢ƒå˜é‡è·å–æ‘˜è¦ç”Ÿæˆå™¨"""
    provider = os.getenv('AI_PROVIDER', 'claude')  # é»˜è®¤ç”¨ Claude

    # ä¼˜å…ˆè·å–ç‰¹å®š provider çš„ API keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ OPENAI_API_KEY
    api_key = os.getenv(f'{provider.upper()}_API_KEY', '') or os.getenv('OPENAI_API_KEY', '')

    # è·å–æ¨¡å‹åç§°
    model = os.getenv(f'{provider.upper()}_MODEL', None) or os.getenv('OPENAI_MODEL', None)

    # å¦‚æœéƒ½æ²¡è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not model:
        model = {
            'claude': 'claude-sonnet-4-20250514',
            'gemini': 'gemini-2.0-flash-exp',
            'openai': 'gpt-4o'
        }.get(provider, 'claude-sonnet-4-20250514')

    return AISummarizer(provider=provider, api_key=api_key, model=model)
